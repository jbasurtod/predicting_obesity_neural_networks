{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Risk Prediction with Neural Networks and Hyperparameter Tuning\n",
    "\n",
    "## Introduction\n",
    "In this Kaggle notebook, I analyze the Estimation of Obesity Levels [dataset](https://archive.ics.uci.edu/dataset/544/estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition) from the UC Irvine Machine Learning Repository dataset. This dataset offers insights into how eating habits and physical conditions correlate with obesity levels, with the goal of building effective predictive models.\n",
    "\n",
    "You can check this model in action in [this Streamlit App](https://obesitypred.streamlit.app/).\n",
    "\n",
    "## Dataset Overview\n",
    "We are using a custom-modified version of the dataset that I uploaded to Kaggle, which includes:\n",
    "\n",
    "- **original_data.csv**: Raw data with random NULL values.\n",
    "- **data_ready.csv**: A cleaned and imputed subset of 1,000 samples for model training and testing. Columns 'gender' and 'Weight' were removed to enhance model performance and avoid collinearity.\n",
    "- **test_later.csv**: Additional data for final model evaluation.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "Two neural network models were trained and tuned. The key results for the best performing neural network are:\n",
    "\n",
    "### On `data_ready.csv`:\n",
    "- **Accuracy**: 0.69\n",
    "\n",
    "|              | precision | recall | f1-score | support |\n",
    "|--------------|-----------|--------|----------|---------|\n",
    "| **0**        | 0.88      | 0.45   | 0.60     | 102     |\n",
    "| **1**        | 0.62      | 0.94   | 0.75     | 98      |\n",
    "| **accuracy** |           |        | 0.69     | 200     |\n",
    "| **macro avg**| 0.75      | 0.69   | 0.67     | 200     |\n",
    "| **weighted avg**| 0.76  | 0.69   | 0.67     | 200     |\n",
    "\n",
    "### On `test_later.csv`:\n",
    "- **Accuracy**: 0.75\n",
    "\n",
    "|              | precision | recall | f1-score | support |\n",
    "|--------------|-----------|--------|----------|---------|\n",
    "| **0**        | 0.93      | 0.56   | 0.70     | 539     |\n",
    "| **1**        | 0.67      | 0.96   | 0.78     | 491     |\n",
    "| **accuracy** |           |        | 0.75     | 1030    |\n",
    "| **macro avg**| 0.80      | 0.76   | 0.74     | 1030    |\n",
    "| **weighted avg**| 0.81  | 0.75   | 0.74     | 1030    |\n",
    "\n",
    "\n",
    "These have been the results for a default threshold of 0.5. However, at its optimal threshold calculated below, a better generalization that balances the classes 0 and 1 is achieved though the recall performance of the class 1 decreases to 0.86.\n",
    "\n",
    "The recall for identifying obesity, our primary objective, shows a strong performance, reflecting the model’s effectiveness in detecting individuals with obesity. This notebook details the model development process, including data preprocessing, feature engineering, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 21:49:22.651570: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-10 21:49:22.652017: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-10 21:49:22.654275: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-10 21:49:22.661298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-10 21:49:22.671564: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-10 21:49:22.674365: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-10 21:49:22.681777: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-10 21:49:23.193620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_selection import f_classif\n",
    "from keras_tuner import RandomSearch, HyperModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(datos_input, var_cont, var_categ):\n",
    "    di_cont = []\n",
    "    di_cat = []\n",
    "    if len(var_cont) != 0:\n",
    "        di_cont = pd.DataFrame(datos_input[var_cont], columns = var_cont)\n",
    "    if len(var_categ) != 0:\n",
    "        di_cat = datos_input[var_categ]\n",
    "        di_cat = pd.get_dummies(di_cat, columns = var_categ, drop_first = True, dtype=int)\n",
    "    if len(var_cont) == 0:\n",
    "        data_input = pd.concat([di_cat], axis=1)\n",
    "    elif len(var_categ) == 0:\n",
    "        data_input = pd.concat([di_cont], axis=1)\n",
    "    else:\n",
    "        data_input = pd.concat([di_cont,di_cat], axis=1)\n",
    "    return data_input, di_cont, di_cat\n",
    "def convert_binary_columns_to_str(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].dropna().unique()\n",
    "        # Check if the column contains exactly two unique values and they are 0 and 1\n",
    "        if len(unique_values) == 2 and set(unique_values) == {0, 1}:\n",
    "            # Convert the column to type str\n",
    "            df[column] = df[column].astype(str)\n",
    "    return df\n",
    "def DataPrep(data, data2):\n",
    "    y = data['NObeyesdad'].astype(int)\n",
    "    del data['NObeyesdad']\n",
    "    y2 = data2['NObeyesdad']\n",
    "    del data2['NObeyesdad']\n",
    "    data = convert_binary_columns_to_str(data)\n",
    "    data2 = convert_binary_columns_to_str(data2)\n",
    "    categ = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    cont = data.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    data_inputn, di_contn, di_catn = prep_data(data, cont, categ)\n",
    "    X = data_inputn.copy()\n",
    "    X2 = data2.copy()\n",
    "    inputs, cont, categ = prep_data(X2, cont, categ)\n",
    "    return X, y, inputs, y2\n",
    "def TestModelAccuracy(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert probabilities to binary class labels\n",
    "    y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "def plot_accuracy_recall_vs_threshold(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Plot accuracy and recall as a function of different threshold values.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained Keras model\n",
    "        The trained Sequential model.\n",
    "    X_test : numpy array or pandas DataFrame\n",
    "        The test features.\n",
    "    y_test : numpy array or pandas Series\n",
    "        The true labels for the test set.\n",
    "    \"\"\"\n",
    "    # Get the predicted probabilities for the positive class\n",
    "    y_prob = model.predict(X_test).ravel()  # Flatten the array if it's 2D with a single column\n",
    "\n",
    "    # Define a range of threshold values from 0 to 1\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Initialize lists to store metrics\n",
    "    accuracies = []\n",
    "    recalls = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # Apply the threshold to get binary predictions\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calculate accuracy and recall\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "        # Append metrics to lists\n",
    "        accuracies.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    # Plot accuracy and recall vs. threshold\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, accuracies, label='Accuracy', color='blue')\n",
    "    plt.plot(thresholds, recalls, label='Recall', color='red')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Accuracy and Recall vs. Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "def find_optimal_threshold(model, X_test, y_test, min_precision=0.7):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for a given model to maximize recall while maintaining a minimum precision.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained Keras model\n",
    "        The trained Sequential model.\n",
    "    X_test : numpy array or pandas DataFrame\n",
    "        The test features.\n",
    "    y_test : numpy array or pandas Series\n",
    "        The true labels for the test set.\n",
    "    min_precision : float\n",
    "        The minimum acceptable precision value.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The optimal threshold value that maximizes recall while maintaining the minimum precision.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the predicted probabilities for the positive class\n",
    "    y_prob = model.predict(X_test).ravel()  # Flatten the array if it's 2D with a single column\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "    # Find the threshold that maximizes recall while keeping precision above min_precision\n",
    "    optimal_threshold = None\n",
    "    max_recall = 0\n",
    "\n",
    "    for i in range(len(precision)):\n",
    "        if precision[i] >= min_precision:\n",
    "            optimal_threshold = thresholds[i] if i < len(thresholds) else 1.0\n",
    "            max_recall = recall[i]\n",
    "            break\n",
    "\n",
    "    print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "    print(f\"Precision at Optimal Threshold: {precision[i]}\")\n",
    "    print(f\"Max Recall at Optimal Threshold: {max_recall}\")\n",
    "\n",
    "    return optimal_threshold\n",
    "def TestModel_Threshold(model, x, y, umbral):\n",
    "    \"\"\"\n",
    "    Evaluate the model with a custom threshold and print the classification report.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained Keras model\n",
    "        The trained Sequential model.\n",
    "    x : numpy array or pandas DataFrame\n",
    "        The test features.\n",
    "    y : numpy array or pandas Series\n",
    "        The true labels for the test set.\n",
    "    umbral : float\n",
    "        The custom threshold to apply.\n",
    "    \"\"\"\n",
    "    # Make predictions (probabilities)\n",
    "    probabilities = model.predict(x).ravel()  # Flatten the array if it's 2D with a single column\n",
    "    \n",
    "    # Define a custom threshold\n",
    "    custom_threshold = umbral\n",
    "    \n",
    "    # Apply the custom threshold\n",
    "    predictions = (probabilities >= custom_threshold).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y, predictions))\n",
    "    # Print classification report\n",
    "    print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "As mentioned above, I am using a modified version of the Estimation of Obesity Levels Based On Eating Habits and Physical Condition from UC Irvine. I will upload a notebook with the respective EDA in the future :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>SCC</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.738469</td>\n",
       "      <td>1.759933</td>\n",
       "      <td>2.627031</td>\n",
       "      <td>3.832911</td>\n",
       "      <td>2.993448</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.425903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.721964</td>\n",
       "      <td>1.918859</td>\n",
       "      <td>2.041376</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.120213</td>\n",
       "      <td>1.055450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.825393</td>\n",
       "      <td>1.603501</td>\n",
       "      <td>2.996186</td>\n",
       "      <td>1.134042</td>\n",
       "      <td>1.270166</td>\n",
       "      <td>0.073065</td>\n",
       "      <td>1.551934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.811580</td>\n",
       "      <td>1.741193</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.768111</td>\n",
       "      <td>0.616503</td>\n",
       "      <td>0.968151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age    Height      FCVC       NCP      CH2O       FAF       TUE  \\\n",
       "0  20.738469  1.759933  2.627031  3.832911  2.993448  2.000000  1.425903   \n",
       "1  29.721964  1.918859  2.041376  3.000000  1.120213  1.055450  0.000000   \n",
       "2  24.825393  1.603501  2.996186  1.134042  1.270166  0.073065  1.551934   \n",
       "3  20.811580  1.741193  3.000000  3.000000  1.768111  0.616503  0.968151   \n",
       "4  18.000000  1.770000  3.000000  3.000000  2.000000  1.000000  1.000000   \n",
       "\n",
       "   family_history_with_overweight  FAVC       CAEC  SMOKE  SCC  \\\n",
       "0                               1     1  Sometimes      0    0   \n",
       "1                               1     1  Sometimes      0    0   \n",
       "2                               1     1  Sometimes      0    0   \n",
       "3                               1     1  Sometimes      0    0   \n",
       "4                               1     1  Sometimes      0    0   \n",
       "\n",
       "                          CALC                    MTRANS  NObeyesdad  \n",
       "0                           no  Public_Transport_Walking         0.0  \n",
       "1  Sometimes_Frequently_Always  Public_Transport_Walking         1.0  \n",
       "2                           no  Public_Transport_Walking         1.0  \n",
       "3  Sometimes_Frequently_Always  Public_Transport_Walking         1.0  \n",
       "4  Sometimes_Frequently_Always  Public_Transport_Walking         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_ready.csv')\n",
    "data2 = pd.read_csv('data/test_later.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, inputs, y2 = DataPrep(data, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "inputs = inputs[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'family_history_with_overweight_1', 'FAVC_1', 'CAEC_Sometimes',\n",
       "       'SCC_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traininig the Neural Network\n",
    "Let's train the first Neural Network with only 1 hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FirstNN(X_train, y_train):\n",
    "    # Red Neuronal con una sola capa oculta\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer with 64 neurons\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model with AUC as a metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[Recall()])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723319363.672526   20023 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-10 21:49:23.672804: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.9417 - recall: 0.7726 - val_loss: 0.6833 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7054 - recall: 0.2175 - val_loss: 0.6840 - val_recall: 0.1311\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6861 - recall: 0.0561 - val_loss: 0.6859 - val_recall: 0.9836\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6871 - recall: 0.6389 - val_loss: 0.6802 - val_recall: 0.9836\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6747 - recall: 0.6061 - val_loss: 0.6626 - val_recall: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6687 - recall: 0.3174 - val_loss: 0.6585 - val_recall: 0.0984\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6618 - recall: 0.2687 - val_loss: 0.6536 - val_recall: 0.1311\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6549 - recall: 0.4104 - val_loss: 0.6468 - val_recall: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6499 - recall: 0.2325 - val_loss: 0.6511 - val_recall: 0.7377\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6403 - recall: 0.8926 - val_loss: 0.6390 - val_recall: 0.0492\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6420 - recall: 0.2186 - val_loss: 0.6465 - val_recall: 0.8689\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6277 - recall: 0.6389 - val_loss: 0.6459 - val_recall: 0.8689\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6274 - recall: 0.8939 - val_loss: 0.6323 - val_recall: 0.7213\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6181 - recall: 0.7627 - val_loss: 0.6291 - val_recall: 0.7869\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6070 - recall: 0.8588 - val_loss: 0.6233 - val_recall: 0.7377\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5958 - recall: 0.7520 - val_loss: 0.6393 - val_recall: 0.9672\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6048 - recall: 0.8079 - val_loss: 0.6217 - val_recall: 0.8689\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5977 - recall: 0.9023 - val_loss: 0.6102 - val_recall: 0.6230\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5890 - recall: 0.8076 - val_loss: 0.6129 - val_recall: 0.8689\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5913 - recall: 0.8620 - val_loss: 0.6031 - val_recall: 0.7213\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5873 - recall: 0.7759 - val_loss: 0.6029 - val_recall: 0.7705\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5863 - recall: 0.8306 - val_loss: 0.6041 - val_recall: 0.8689\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5739 - recall: 0.8723 - val_loss: 0.6037 - val_recall: 0.8689\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5873 - recall: 0.8515 - val_loss: 0.6071 - val_recall: 0.9016\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5587 - recall: 0.8967 - val_loss: 0.5892 - val_recall: 0.8197\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5618 - recall: 0.8623 - val_loss: 0.5948 - val_recall: 0.8689\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5847 - recall: 0.8476 - val_loss: 0.6078 - val_recall: 0.9672\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5640 - recall: 0.9189 - val_loss: 0.5889 - val_recall: 0.8689\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5629 - recall: 0.8732 - val_loss: 0.5782 - val_recall: 0.5082\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5782 - recall: 0.7209 - val_loss: 0.5730 - val_recall: 0.7213\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5736 - recall: 0.7720 - val_loss: 0.5723 - val_recall: 0.7377\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5684 - recall: 0.6989 - val_loss: 0.5964 - val_recall: 0.9672\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5480 - recall: 0.9224 - val_loss: 0.5700 - val_recall: 0.8689\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5425 - recall: 0.9098 - val_loss: 0.5641 - val_recall: 0.7213\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5435 - recall: 0.8054 - val_loss: 0.5832 - val_recall: 0.9672\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5436 - recall: 0.8830 - val_loss: 0.5610 - val_recall: 0.8689\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5240 - recall: 0.8860 - val_loss: 0.5644 - val_recall: 0.8689\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - loss: 0.5574 - recall: 0.8760 - val_loss: 0.5633 - val_recall: 0.8689\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5311 - recall: 0.8876 - val_loss: 0.5764 - val_recall: 0.9672\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.5263 - recall: 0.9425 - val_loss: 0.5670 - val_recall: 0.9508\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5377 - recall: 0.9596 - val_loss: 0.5472 - val_recall: 0.8361\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5131 - recall: 0.9042 - val_loss: 0.5544 - val_recall: 0.9016\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5272 - recall: 0.9055 - val_loss: 0.5452 - val_recall: 0.8689\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5318 - recall: 0.8689 - val_loss: 0.5582 - val_recall: 0.9672\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5231 - recall: 0.9430 - val_loss: 0.5510 - val_recall: 0.9016\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5121 - recall: 0.9578 - val_loss: 0.5425 - val_recall: 0.7213\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5282 - recall: 0.7960 - val_loss: 0.5428 - val_recall: 0.9016\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5214 - recall: 0.9349 - val_loss: 0.5369 - val_recall: 0.7377\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5242 - recall: 0.8195 - val_loss: 0.5348 - val_recall: 0.8689\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5001 - recall: 0.9156 - val_loss: 0.5351 - val_recall: 0.7213\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5195 - recall: 0.8316 - val_loss: 0.5362 - val_recall: 0.9016\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 0.4968 - recall: 0.9464 - val_loss: 0.5328 - val_recall: 0.9016\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5076 - recall: 0.9485 - val_loss: 0.5317 - val_recall: 0.9016\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5032 - recall: 0.9368 - val_loss: 0.5300 - val_recall: 0.9016\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4945 - recall: 0.9418 - val_loss: 0.5334 - val_recall: 0.9672\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5151 - recall: 0.9507 - val_loss: 0.5253 - val_recall: 0.8689\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.5159 - recall: 0.8690 - val_loss: 0.5205 - val_recall: 0.8689\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5194 - recall: 0.8757 - val_loss: 0.5218 - val_recall: 0.8689\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5080 - recall: 0.8914 - val_loss: 0.5407 - val_recall: 0.9672\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4999 - recall: 0.9468 - val_loss: 0.5243 - val_recall: 0.9508\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4933 - recall: 0.9579 - val_loss: 0.5192 - val_recall: 0.9672\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.4914 - recall: 0.9407 - val_loss: 0.5276 - val_recall: 0.9672\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.5182 - recall: 0.9502 - val_loss: 0.5267 - val_recall: 0.9672\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - loss: 0.5046 - recall: 0.9759 - val_loss: 0.5184 - val_recall: 0.9672\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5037 - recall: 0.9613 - val_loss: 0.5148 - val_recall: 0.9672\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4989 - recall: 0.9688 - val_loss: 0.5089 - val_recall: 0.8689\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5001 - recall: 0.8956 - val_loss: 0.5361 - val_recall: 0.9672\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.4918 - recall: 0.9603 - val_loss: 0.5098 - val_recall: 0.9344\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4986 - recall: 0.9370 - val_loss: 0.5125 - val_recall: 0.9672\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.4772 - recall: 0.9759 - val_loss: 0.5055 - val_recall: 0.8689\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4897 - recall: 0.9036 - val_loss: 0.5038 - val_recall: 0.9344\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.4770 - recall: 0.9744 - val_loss: 0.5025 - val_recall: 0.8689\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4819 - recall: 0.9129 - val_loss: 0.5085 - val_recall: 0.9672\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4901 - recall: 0.9535 - val_loss: 0.5161 - val_recall: 0.9672\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 0.4818 - recall: 0.9582 - val_loss: 0.5043 - val_recall: 0.9016\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - loss: 0.4901 - recall: 0.9362 - val_loss: 0.5047 - val_recall: 0.9672\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4674 - recall: 0.9686 - val_loss: 0.4987 - val_recall: 0.9180\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4769 - recall: 0.9637 - val_loss: 0.5099 - val_recall: 0.9672\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 0.4862 - recall: 0.9651 - val_loss: 0.5036 - val_recall: 0.9672\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4897 - recall: 0.9578 - val_loss: 0.4952 - val_recall: 0.9016\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - loss: 0.4715 - recall: 0.9505 - val_loss: 0.4950 - val_recall: 0.8689\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - loss: 0.4870 - recall: 0.9201 - val_loss: 0.4942 - val_recall: 0.8852\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4665 - recall: 0.9189 - val_loss: 0.4937 - val_recall: 0.8689\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5021 - recall: 0.9301 - val_loss: 0.4924 - val_recall: 0.9016\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4871 - recall: 0.9302 - val_loss: 0.4955 - val_recall: 0.9672\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.4790 - recall: 0.9665 - val_loss: 0.4927 - val_recall: 0.9672\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - loss: 0.4709 - recall: 0.9529 - val_loss: 0.4970 - val_recall: 0.9672\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4630 - recall: 0.9617 - val_loss: 0.4998 - val_recall: 0.9672\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4789 - recall: 0.9695 - val_loss: 0.4991 - val_recall: 0.9672\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4989 - recall: 0.9440 - val_loss: 0.5485 - val_recall: 0.9672\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - loss: 0.4904 - recall: 0.9541 - val_loss: 0.4952 - val_recall: 0.9672\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4816 - recall: 0.9637 - val_loss: 0.4925 - val_recall: 0.9672\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.4889 - recall: 0.9593 - val_loss: 0.4872 - val_recall: 0.9672\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4794 - recall: 0.9510 - val_loss: 0.4987 - val_recall: 0.9672\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4733 - recall: 0.9418 - val_loss: 0.5127 - val_recall: 0.9672\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4847 - recall: 0.9612 - val_loss: 0.4854 - val_recall: 0.9016\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4421 - recall: 0.9614 - val_loss: 0.4936 - val_recall: 0.9672\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4745 - recall: 0.9662 - val_loss: 0.4869 - val_recall: 0.9672\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4750 - recall: 0.9418 - val_loss: 0.5168 - val_recall: 0.9672\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4873 - recall: 0.9520 - val_loss: 0.5230 - val_recall: 0.9672\n"
     ]
    }
   ],
   "source": [
    "model1 = FirstNN(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Now, we will dive into Hyperparameter Tuning using 2 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "def HyperModel(hp):\n",
    "    model = Sequential()\n",
    "    # Tune the number of units in the first hidden layer\n",
    "    hp_units_1 = hp.Int('units_1', min_value=10, max_value=100, step=10)\n",
    "    model.add(Dense(units=hp_units_1, activation='relu', input_dim=X_train.shape[1]))\n",
    "    \n",
    "    # Tune the number of units in the second hidden layer\n",
    "    hp_units_2 = hp.Int('units_2', min_value=10, max_value=100, step=10)\n",
    "    model.add(Dense(units=hp_units_2, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[Recall()])\n",
    "    return model\n",
    "tuner = RandomSearch(\n",
    "    HyperModel,\n",
    "    objective='val_recall',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8405 - recall_2: 0.4939 - val_loss: 0.6738 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6925 - recall_2: 0.0756 - val_loss: 0.7406 - val_recall_2: 1.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7148 - recall_2: 0.7022 - val_loss: 0.7021 - val_recall_2: 1.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6774 - recall_2: 0.7548 - val_loss: 0.6682 - val_recall_2: 0.7213\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6600 - recall_2: 0.7383 - val_loss: 0.6656 - val_recall_2: 0.9836\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6585 - recall_2: 0.7678 - val_loss: 0.6239 - val_recall_2: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6230 - recall_2: 0.3777 - val_loss: 0.6088 - val_recall_2: 0.9344\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5932 - recall_2: 0.9367 - val_loss: 0.5974 - val_recall_2: 0.9672\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5616 - recall_2: 0.8120 - val_loss: 0.6118 - val_recall_2: 0.9672\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5305 - recall_2: 0.7766 - val_loss: 0.5483 - val_recall_2: 0.8689\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5358 - recall_2: 0.8688 - val_loss: 0.5426 - val_recall_2: 0.9344\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4974 - recall_2: 0.9155 - val_loss: 0.5115 - val_recall_2: 0.8689\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5101 - recall_2: 0.9015 - val_loss: 0.5172 - val_recall_2: 0.9016\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5005 - recall_2: 0.9270 - val_loss: 0.4962 - val_recall_2: 0.8525\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4879 - recall_2: 0.8755 - val_loss: 0.5761 - val_recall_2: 0.9672\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5139 - recall_2: 0.6929 - val_loss: 0.5035 - val_recall_2: 0.9672\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4834 - recall_2: 0.9150 - val_loss: 0.5968 - val_recall_2: 0.9836\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5548 - recall_2: 0.7703 - val_loss: 0.4960 - val_recall_2: 0.8689\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5056 - recall_2: 0.7523 - val_loss: 0.4939 - val_recall_2: 0.9672\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4896 - recall_2: 0.9418 - val_loss: 0.4863 - val_recall_2: 0.8361\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4666 - recall_2: 0.8341 - val_loss: 0.4842 - val_recall_2: 0.9016\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4592 - recall_2: 0.9346 - val_loss: 0.5102 - val_recall_2: 0.7377\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4875 - recall_2: 0.8677 - val_loss: 0.4804 - val_recall_2: 0.9508\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5065 - recall_2: 0.8724 - val_loss: 0.5058 - val_recall_2: 0.9672\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4773 - recall_2: 0.8758 - val_loss: 0.6496 - val_recall_2: 0.9836\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5377 - recall_2: 0.8361 - val_loss: 0.4937 - val_recall_2: 0.9672\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4688 - recall_2: 0.9718 - val_loss: 0.4811 - val_recall_2: 0.9672\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4662 - recall_2: 0.9556 - val_loss: 0.4893 - val_recall_2: 0.9672\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4822 - recall_2: 0.9456 - val_loss: 0.4791 - val_recall_2: 0.8361\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4560 - recall_2: 0.9122 - val_loss: 0.5054 - val_recall_2: 0.9672\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5117 - recall_2: 0.8582 - val_loss: 0.5104 - val_recall_2: 0.7213\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4987 - recall_2: 0.8430 - val_loss: 0.4706 - val_recall_2: 0.9508\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4961 - recall_2: 0.9398 - val_loss: 0.4921 - val_recall_2: 0.9672\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4448 - recall_2: 0.9436 - val_loss: 0.4822 - val_recall_2: 0.9672\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4737 - recall_2: 0.7949 - val_loss: 0.4815 - val_recall_2: 0.9016\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4526 - recall_2: 0.9742 - val_loss: 0.4774 - val_recall_2: 0.9672\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4695 - recall_2: 0.9574 - val_loss: 0.4629 - val_recall_2: 0.9016\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4321 - recall_2: 0.9350 - val_loss: 0.5078 - val_recall_2: 0.9672\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4852 - recall_2: 0.8985 - val_loss: 0.4939 - val_recall_2: 0.9672\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4410 - recall_2: 0.9790 - val_loss: 0.4936 - val_recall_2: 0.9672\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4713 - recall_2: 0.9037 - val_loss: 0.4922 - val_recall_2: 0.9672\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5184 - recall_2: 0.9004 - val_loss: 0.4746 - val_recall_2: 0.9672\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4540 - recall_2: 0.9350 - val_loss: 0.4719 - val_recall_2: 0.9672\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4719 - recall_2: 0.9112 - val_loss: 0.4712 - val_recall_2: 0.9672\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4592 - recall_2: 0.9438 - val_loss: 0.5572 - val_recall_2: 0.9672\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4815 - recall_2: 0.9212 - val_loss: 0.4624 - val_recall_2: 0.8852\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4723 - recall_2: 0.7664 - val_loss: 0.4861 - val_recall_2: 0.9672\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4627 - recall_2: 0.9529 - val_loss: 0.4933 - val_recall_2: 0.9672\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4669 - recall_2: 0.9505 - val_loss: 0.4594 - val_recall_2: 0.8525\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4765 - recall_2: 0.8373 - val_loss: 0.4662 - val_recall_2: 0.9508\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4688 - recall_2: 0.8968 - val_loss: 0.5015 - val_recall_2: 0.9672\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4708 - recall_2: 0.9461 - val_loss: 0.4657 - val_recall_2: 0.9672\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4554 - recall_2: 0.9210 - val_loss: 0.5490 - val_recall_2: 0.9672\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4934 - recall_2: 0.9525 - val_loss: 0.4550 - val_recall_2: 0.9016\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4567 - recall_2: 0.9024 - val_loss: 0.4600 - val_recall_2: 0.9180\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4984 - recall_2: 0.8611 - val_loss: 0.4853 - val_recall_2: 0.9672\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4542 - recall_2: 0.9133 - val_loss: 0.4770 - val_recall_2: 0.9672\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5031 - recall_2: 0.8553 - val_loss: 0.4581 - val_recall_2: 0.9180\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4400 - recall_2: 0.8610 - val_loss: 0.4667 - val_recall_2: 0.9672\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4589 - recall_2: 0.8993 - val_loss: 0.4936 - val_recall_2: 0.9672\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4657 - recall_2: 0.9382 - val_loss: 0.4527 - val_recall_2: 0.8033\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4759 - recall_2: 0.8629 - val_loss: 0.4868 - val_recall_2: 0.9672\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4565 - recall_2: 0.9300 - val_loss: 0.4623 - val_recall_2: 0.9344\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4389 - recall_2: 0.8919 - val_loss: 0.4977 - val_recall_2: 0.9672\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4802 - recall_2: 0.9095 - val_loss: 0.4544 - val_recall_2: 0.9016\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4752 - recall_2: 0.8277 - val_loss: 0.4571 - val_recall_2: 0.8689\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4526 - recall_2: 0.8625 - val_loss: 0.4886 - val_recall_2: 0.9672\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.4273 - recall_2: 0.9362 - val_loss: 0.4720 - val_recall_2: 0.9508\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4276 - recall_2: 0.8748 - val_loss: 0.4944 - val_recall_2: 0.9672\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 0.4326 - recall_2: 0.9384 - val_loss: 0.4692 - val_recall_2: 0.9508\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - loss: 0.4630 - recall_2: 0.8789 - val_loss: 0.4551 - val_recall_2: 0.9180\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.4594 - recall_2: 0.8753 - val_loss: 0.4895 - val_recall_2: 0.9672\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4843 - recall_2: 0.9128 - val_loss: 0.4983 - val_recall_2: 0.9672\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4584 - recall_2: 0.8746 - val_loss: 0.4579 - val_recall_2: 0.9180\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4633 - recall_2: 0.8054 - val_loss: 0.4941 - val_recall_2: 0.9672\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4549 - recall_2: 0.9329 - val_loss: 0.4713 - val_recall_2: 0.9508\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - loss: 0.4374 - recall_2: 0.9285 - val_loss: 0.4516 - val_recall_2: 0.8852\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 0.4542 - recall_2: 0.9050 - val_loss: 0.4568 - val_recall_2: 0.9180\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4809 - recall_2: 0.8451 - val_loss: 0.4834 - val_recall_2: 0.9672\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4312 - recall_2: 0.9430 - val_loss: 0.4604 - val_recall_2: 0.8852\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4421 - recall_2: 0.8068 - val_loss: 0.4524 - val_recall_2: 0.8689\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4275 - recall_2: 0.8797 - val_loss: 0.4958 - val_recall_2: 0.9672\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4326 - recall_2: 0.9327 - val_loss: 0.4656 - val_recall_2: 0.9672\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4314 - recall_2: 0.8749 - val_loss: 0.5447 - val_recall_2: 0.9836\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - loss: 0.4677 - recall_2: 0.9473 - val_loss: 0.4584 - val_recall_2: 0.9508\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4422 - recall_2: 0.9106 - val_loss: 0.4788 - val_recall_2: 0.9672\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4665 - recall_2: 0.8898 - val_loss: 0.4784 - val_recall_2: 0.9508\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4644 - recall_2: 0.8839 - val_loss: 0.4801 - val_recall_2: 0.9016\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4347 - recall_2: 0.9278 - val_loss: 0.4796 - val_recall_2: 0.7377\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - loss: 0.4848 - recall_2: 0.8283 - val_loss: 0.5151 - val_recall_2: 0.9672\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4731 - recall_2: 0.9012 - val_loss: 0.4617 - val_recall_2: 0.6721\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4751 - recall_2: 0.7496 - val_loss: 0.4884 - val_recall_2: 0.9672\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4295 - recall_2: 0.9453 - val_loss: 0.4542 - val_recall_2: 0.8689\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4463 - recall_2: 0.8140 - val_loss: 0.5221 - val_recall_2: 0.9672\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4235 - recall_2: 0.9126 - val_loss: 0.4753 - val_recall_2: 0.9672\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4431 - recall_2: 0.8716 - val_loss: 0.4634 - val_recall_2: 0.9180\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4343 - recall_2: 0.7991 - val_loss: 0.4642 - val_recall_2: 0.9344\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.4499 - recall_2: 0.8966 - val_loss: 0.5224 - val_recall_2: 0.9836\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4297 - recall_2: 0.8996 - val_loss: 0.4729 - val_recall_2: 0.8033\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.4900 - recall_2: 0.8013 - val_loss: 0.4864 - val_recall_2: 0.9672\n"
     ]
    }
   ],
   "source": [
    "modelBest = tuner.hypermodel.build(best_hps)\n",
    "history = modelBest.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Models\n",
    "Now that we have the models ready, we will test them with the train data and with the additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "AUC: 0.69\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, (model1.predict(X_test) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263us/step\n",
      "AUC: 0.76\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y2, (model1.predict(inputs) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step\n",
      "Accuracy: 0.69\n",
      "[[46 56]\n",
      " [ 6 92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60       102\n",
      "           1       0.62      0.94      0.75        98\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.75      0.69      0.67       200\n",
      "weighted avg       0.76      0.69      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(model1,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step\n",
      "Accuracy: 0.7504854368932039\n",
      "[[304 235]\n",
      " [ 22 469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.56      0.70       539\n",
      "           1       0.67      0.96      0.78       491\n",
      "\n",
      "    accuracy                           0.75      1030\n",
      "   macro avg       0.80      0.76      0.74      1030\n",
      "weighted avg       0.81      0.75      0.74      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(model1,inputs,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "AUC: 0.71\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, (modelBest.predict(X_test) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step\n",
      "AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y2, (modelBest.predict(inputs) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step\n",
      "Accuracy: 0.705\n",
      "[[50 52]\n",
      " [ 7 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.49      0.63       102\n",
      "           1       0.64      0.93      0.76        98\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.76      0.71      0.69       200\n",
      "weighted avg       0.76      0.70      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(modelBest,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step\n",
      "Accuracy: 0.7592233009708738\n",
      "[[315 224]\n",
      " [ 24 467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.58      0.72       539\n",
      "           1       0.68      0.95      0.79       491\n",
      "\n",
      "    accuracy                           0.76      1030\n",
      "   macro avg       0.80      0.77      0.75      1030\n",
      "weighted avg       0.81      0.76      0.75      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(modelBest,inputs,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Optimal Threshold\n",
    "Finding the optimal threshold for this exercise is about finding the sweet spot in which we maximize the recall for class 1 and class 0, while we try to improve accuracy as much as we can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step\n",
      "Optimal Threshold: 0.6250295042991638\n",
      "Precision at Optimal Threshold: 0.7009345794392523\n",
      "Max Recall at Optimal Threshold: 0.7637474541751528\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = find_optimal_threshold(modelBest,inputs,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_recall_vs_threshold(modelBest, inputs, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step\n",
      "Accuracy: 0.7543689320388349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73       539\n",
      "           1       0.69      0.89      0.78       491\n",
      "\n",
      "    accuracy                           0.75      1030\n",
      "   macro avg       0.77      0.76      0.75      1030\n",
      "weighted avg       0.78      0.75      0.75      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The best threshold seems to be around 0.55\n",
    "TestModel_Threshold(modelBest, inputs, y2,0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "Accuracy: 0.7320388349514563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       539\n",
      "           1       0.70      0.76      0.73       491\n",
      "\n",
      "    accuracy                           0.73      1030\n",
      "   macro avg       0.73      0.73      0.73      1030\n",
      "weighted avg       0.73      0.73      0.73      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The optimal threshold that comes from the function\n",
    "TestModel_Threshold(modelBest,inputs, y2,optimal_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "This analysis demonstrates the effectiveness of neural networks in predicting obesity levels based on eating habits and physical conditions. The best-performing neural network model achieved an accuracy of 0.69 on the training data (`data_ready.csv`) and 0.75 on the additional test data (`test_later.csv`), indicating a reasonable generalization to new data.\n",
    "\n",
    "### Key Findings:\n",
    "1. **Recall for Identifying Obesity**: The model showed a strong recall score of 0.94 on the training set and 0.96 on the test set for the class identifying obesity. This reflects the model's high effectiveness in correctly identifying individuals with obesity, which is crucial for early intervention and treatment.\n",
    "\n",
    "2. **Optimal Threshold**: The model's performance is balanced and achieves a better generalization at a threshold of around 0.61, however we have favored the class 1 by setting it at 0.55 for the Streamlit App.\n",
    "  \n",
    "3. **Model Performance**: Despite the high recall, the overall accuracy was moderate, indicating potential room for improvement in terms of precision and reducing false positives. The confusion matrix analysis reveals that while the model is adept at identifying true cases of obesity, there are still challenges in accurately predicting non-obese individuals.\n",
    "  \n",
    "4. **Feature Impact**: The neural network models' performance underscores the importance of feature selection and preprocessing. The exclusion of certain features like 'gender' and 'Weight' was aimed at enhancing model performance and reducing collinearity, which appears to have been effective.\n",
    "\n",
    "### Future Work:\n",
    "- **Hyperparameter Tuning**: Further tuning of the hyperparameters and exploring different architectures of neural networks could lead to improved performance.\n",
    "- **Feature Engineering**: Additional feature engineering and the inclusion of more relevant features could help in boosting model accuracy.\n",
    "- **Ensemble Methods**: Combining neural networks with other models, such as Random Forests, might offer enhanced predictive power through ensemble methods.\n",
    "\n",
    "The results of this study affirm the potential of neural networks in medical and health-related predictive analytics, specifically in the area of obesity risk prediction. The strong recall scores are particularly promising for practical applications where correctly identifying cases of obesity is of paramount importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5493607,
     "sourceId": 9102667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
