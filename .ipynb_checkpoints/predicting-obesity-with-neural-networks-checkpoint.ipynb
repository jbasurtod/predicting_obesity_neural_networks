{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Risk Prediction with Neural Networks, Cross Validation, and Hyperparameter Tuning\n",
    "\n",
    "## Introduction\n",
    "In this Kaggle notebook, I analyze the Estimation of Obesity Levels dataset from the UC Irvine Machine Learning Repository. This dataset offers insights into how eating habits and physical conditions correlate with obesity levels, with the goal of building effective predictive models using neural networks.\n",
    "\n",
    "You can check this model in action in this Streamlit App.\n",
    "\n",
    "## Dataset Overview\n",
    "We are using a custom-modified version of the dataset that I uploaded to Kaggle, which includes:\n",
    "\n",
    "- **original_data.csv**: Raw data with random NULL values.\n",
    "- **data_ready.csv**: A cleaned and imputed subset of 1,000 samples for model training and testing. Columns 'gender' and 'Weight' were removed to enhance model performance and avoid collinearity.\n",
    "- **test_later.csv**: Additional data for final model evaluation.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "Two neural network models were trained and tuned using cross-validation. The key results for the best performing neural network are:\n",
    "\n",
    "### On `data_ready.csv`:\n",
    "- **Accuracy**: 0.69\n",
    "\n",
    "|              | precision | recall | f1-score | support |\n",
    "|--------------|-----------|--------|----------|---------|\n",
    "| **0**        | 0.88      | 0.45   | 0.60     | 102     |\n",
    "| **1**        | 0.62      | 0.94   | 0.75     | 98      |\n",
    "| **accuracy** |           |        | 0.69     | 200     |\n",
    "| **macro avg**| 0.75      | 0.69   | 0.67     | 200     |\n",
    "| **weighted avg**| 0.76  | 0.69   | 0.67     | 200     |\n",
    "\n",
    "### On `test_later.csv`:\n",
    "- **Accuracy**: 0.75\n",
    "\n",
    "|              | precision | recall | f1-score | support |\n",
    "|--------------|-----------|--------|----------|---------|\n",
    "| **0**        | 0.93      | 0.56   | 0.70     | 539     |\n",
    "| **1**        | 0.67      | 0.96   | 0.78     | 491     |\n",
    "| **accuracy** |           |        | 0.75     | 1030    |\n",
    "| **macro avg**| 0.80      | 0.76   | 0.74     | 1030    |\n",
    "| **weighted avg**| 0.81  | 0.75   | 0.74     | 1030    |\n",
    "\n",
    "The recall for identifying obesity, our primary objective, shows a strong performance, reflecting the model’s effectiveness in detecting individuals with obesity. This notebook details the model development process, including data preprocessing, feature engineering, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 14:42:19.513391: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 14:42:19.513856: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 14:42:19.516010: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 14:42:19.522677: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 14:42:19.533580: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 14:42:19.536778: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 14:42:19.545878: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 14:42:20.081513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras_tuner import RandomSearch, HyperModel\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(datos_input, var_cont, var_categ):\n",
    "    di_cont = []\n",
    "    di_cat = []\n",
    "    if len(var_cont) != 0:\n",
    "        di_cont = pd.DataFrame(datos_input[var_cont], columns = var_cont)\n",
    "    if len(var_categ) != 0:\n",
    "        di_cat = datos_input[var_categ]\n",
    "        di_cat = pd.get_dummies(di_cat, columns = var_categ, drop_first = True, dtype=int)\n",
    "    if len(var_cont) == 0:\n",
    "        data_input = pd.concat([di_cat], axis=1)\n",
    "    elif len(var_categ) == 0:\n",
    "        data_input = pd.concat([di_cont], axis=1)\n",
    "    else:\n",
    "        data_input = pd.concat([di_cont,di_cat], axis=1)\n",
    "    return data_input, di_cont, di_cat\n",
    "def convert_binary_columns_to_str(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Iterate through each column in the DataFrame\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].dropna().unique()\n",
    "        # Check if the column contains exactly two unique values and they are 0 and 1\n",
    "        if len(unique_values) == 2 and set(unique_values) == {0, 1}:\n",
    "            # Convert the column to type str\n",
    "            df[column] = df[column].astype(str)\n",
    "    return df\n",
    "def DataPrep(data, data2):\n",
    "    y = data['NObeyesdad'].astype(int)\n",
    "    del data['NObeyesdad']\n",
    "    y2 = data2['NObeyesdad']\n",
    "    del data2['NObeyesdad']\n",
    "    data = convert_binary_columns_to_str(data)\n",
    "    data2 = convert_binary_columns_to_str(data2)\n",
    "    categ = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    cont = data.select_dtypes(exclude=['object', 'category']).columns.tolist()\n",
    "    data_inputn, di_contn, di_catn = prep_data(data, cont, categ)\n",
    "    X = data_inputn.copy()\n",
    "    X2 = data2.copy()\n",
    "    inputs, cont, categ = prep_data(X2, cont, categ)\n",
    "    return X, y, inputs, y2\n",
    "def TestModelAccuracy(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Convert probabilities to binary class labels\n",
    "    y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "As mentioned above, I am using a modified version of the Estimation of Obesity Levels Based On Eating Habits and Physical Condition from UC Irvine. I will upload a notebook with the respective EDA in the future :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>SCC</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.738469</td>\n",
       "      <td>1.759933</td>\n",
       "      <td>2.627031</td>\n",
       "      <td>3.832911</td>\n",
       "      <td>2.993448</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.425903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.721964</td>\n",
       "      <td>1.918859</td>\n",
       "      <td>2.041376</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.120213</td>\n",
       "      <td>1.055450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.825393</td>\n",
       "      <td>1.603501</td>\n",
       "      <td>2.996186</td>\n",
       "      <td>1.134042</td>\n",
       "      <td>1.270166</td>\n",
       "      <td>0.073065</td>\n",
       "      <td>1.551934</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.811580</td>\n",
       "      <td>1.741193</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.768111</td>\n",
       "      <td>0.616503</td>\n",
       "      <td>0.968151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sometimes_Frequently_Always</td>\n",
       "      <td>Public_Transport_Walking</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age    Height      FCVC       NCP      CH2O       FAF       TUE  \\\n",
       "0  20.738469  1.759933  2.627031  3.832911  2.993448  2.000000  1.425903   \n",
       "1  29.721964  1.918859  2.041376  3.000000  1.120213  1.055450  0.000000   \n",
       "2  24.825393  1.603501  2.996186  1.134042  1.270166  0.073065  1.551934   \n",
       "3  20.811580  1.741193  3.000000  3.000000  1.768111  0.616503  0.968151   \n",
       "4  18.000000  1.770000  3.000000  3.000000  2.000000  1.000000  1.000000   \n",
       "\n",
       "   family_history_with_overweight  FAVC       CAEC  SMOKE  SCC  \\\n",
       "0                               1     1  Sometimes      0    0   \n",
       "1                               1     1  Sometimes      0    0   \n",
       "2                               1     1  Sometimes      0    0   \n",
       "3                               1     1  Sometimes      0    0   \n",
       "4                               1     1  Sometimes      0    0   \n",
       "\n",
       "                          CALC                    MTRANS  NObeyesdad  \n",
       "0                           no  Public_Transport_Walking         0.0  \n",
       "1  Sometimes_Frequently_Always  Public_Transport_Walking         1.0  \n",
       "2                           no  Public_Transport_Walking         1.0  \n",
       "3  Sometimes_Frequently_Always  Public_Transport_Walking         1.0  \n",
       "4  Sometimes_Frequently_Always  Public_Transport_Walking         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/data_ready.csv')\n",
    "data2 = pd.read_csv('data/test_later.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, inputs, y2 = DataPrep(data, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "inputs = inputs[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'family_history_with_overweight_1', 'FAVC_1', 'CAEC_Sometimes',\n",
       "       'SCC_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traininig the Neural Network\n",
    "Let's train the first Neural Network with only 1 hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FirstNN(X_train, y_train):\n",
    "    # Red Neuronal con una sola capa oculta\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer with 64 neurons\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
    "    \n",
    "    # Compile the model with AUC as a metric\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=[Recall()])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancarlos/anaconda3/envs/mldev/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722948140.579208   87226 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-06 14:42:20.579492: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.8954 - recall: 1.0000 - val_loss: 1.1732 - val_recall: 1.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9101 - recall: 0.7162 - val_loss: 0.7244 - val_recall: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7661 - recall: 0.0305 - val_loss: 0.7161 - val_recall: 0.5902\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7192 - recall: 0.3756 - val_loss: 0.6888 - val_recall: 0.0820\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7147 - recall: 0.0567 - val_loss: 0.6879 - val_recall: 0.1148\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6997 - recall: 0.0815 - val_loss: 0.6817 - val_recall: 0.0984\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6884 - recall: 0.1197 - val_loss: 0.6783 - val_recall: 0.1148\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6909 - recall: 0.0511 - val_loss: 0.6719 - val_recall: 0.0164\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6812 - recall: 0.2197 - val_loss: 0.6670 - val_recall: 0.0164\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6759 - recall: 0.0384 - val_loss: 0.6663 - val_recall: 0.0820\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6685 - recall: 0.0939 - val_loss: 0.6659 - val_recall: 0.2623\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6597 - recall: 0.0523 - val_loss: 0.6563 - val_recall: 0.0164\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6609 - recall: 0.2832 - val_loss: 0.6506 - val_recall: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6615 - recall: 0.4070 - val_loss: 0.6462 - val_recall: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6444 - recall: 0.1577 - val_loss: 0.6501 - val_recall: 0.8852\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6395 - recall: 0.6430 - val_loss: 0.6487 - val_recall: 0.9180\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6437 - recall: 0.9163 - val_loss: 0.6429 - val_recall: 0.8689\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6316 - recall: 0.7159 - val_loss: 0.6368 - val_recall: 0.7213\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6237 - recall: 0.7005 - val_loss: 0.6331 - val_recall: 0.7213\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6169 - recall: 0.8917 - val_loss: 0.6261 - val_recall: 0.1803\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6320 - recall: 0.5925 - val_loss: 0.6294 - val_recall: 0.8361\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6176 - recall: 0.8562 - val_loss: 0.6308 - val_recall: 0.8689\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6141 - recall: 0.8419 - val_loss: 0.6194 - val_recall: 0.7213\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6006 - recall: 0.8443 - val_loss: 0.6283 - val_recall: 0.8689\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6072 - recall: 0.8407 - val_loss: 0.6272 - val_recall: 0.9016\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6021 - recall: 0.9538 - val_loss: 0.6104 - val_recall: 0.3770\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6025 - recall: 0.5593 - val_loss: 0.6111 - val_recall: 0.7377\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5828 - recall: 0.7489 - val_loss: 0.6158 - val_recall: 0.8689\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5920 - recall: 0.8737 - val_loss: 0.6090 - val_recall: 0.8689\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5777 - recall: 0.8612 - val_loss: 0.6206 - val_recall: 0.9344\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5860 - recall: 0.8210 - val_loss: 0.6015 - val_recall: 0.7705\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5906 - recall: 0.9115 - val_loss: 0.6015 - val_recall: 0.7705\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5767 - recall: 0.7807 - val_loss: 0.6027 - val_recall: 0.8689\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5758 - recall: 0.8653 - val_loss: 0.5968 - val_recall: 0.8361\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5670 - recall: 0.8087 - val_loss: 0.5967 - val_recall: 0.8689\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5693 - recall: 0.8772 - val_loss: 0.6020 - val_recall: 0.8689\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5583 - recall: 0.8635 - val_loss: 0.5899 - val_recall: 0.8525\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5714 - recall: 0.8922 - val_loss: 0.5987 - val_recall: 0.8852\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5574 - recall: 0.8943 - val_loss: 0.5862 - val_recall: 0.8525\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5603 - recall: 0.8956 - val_loss: 0.5879 - val_recall: 0.8689\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5801 - recall: 0.8352 - val_loss: 0.5892 - val_recall: 0.8689\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5671 - recall: 0.8933 - val_loss: 0.5929 - val_recall: 0.9016\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5657 - recall: 0.9258 - val_loss: 0.5778 - val_recall: 0.8033\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5573 - recall: 0.8630 - val_loss: 0.5794 - val_recall: 0.8689\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5610 - recall: 0.8701 - val_loss: 0.5837 - val_recall: 0.8689\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5615 - recall: 0.9269 - val_loss: 0.5710 - val_recall: 0.7541\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5621 - recall: 0.8458 - val_loss: 0.5854 - val_recall: 0.9016\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5503 - recall: 0.9020 - val_loss: 0.5696 - val_recall: 0.8689\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5550 - recall: 0.8291 - val_loss: 0.5976 - val_recall: 0.9672\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5520 - recall: 0.9252 - val_loss: 0.5889 - val_recall: 0.9672\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5462 - recall: 0.9314 - val_loss: 0.5633 - val_recall: 0.8033\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5423 - recall: 0.8811 - val_loss: 0.5616 - val_recall: 0.8689\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5582 - recall: 0.8799 - val_loss: 0.5634 - val_recall: 0.8689\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5349 - recall: 0.8908 - val_loss: 0.5801 - val_recall: 0.9672\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5371 - recall: 0.9323 - val_loss: 0.5628 - val_recall: 0.8689\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5207 - recall: 0.8982 - val_loss: 0.5551 - val_recall: 0.8361\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5277 - recall: 0.8627 - val_loss: 0.5734 - val_recall: 0.9672\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5348 - recall: 0.9216 - val_loss: 0.5770 - val_recall: 0.9672\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5378 - recall: 0.9233 - val_loss: 0.5591 - val_recall: 0.9016\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5379 - recall: 0.8742 - val_loss: 0.5902 - val_recall: 0.9672\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5453 - recall: 0.9378 - val_loss: 0.5578 - val_recall: 0.4426\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5480 - recall: 0.7367 - val_loss: 0.5459 - val_recall: 0.8689\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5410 - recall: 0.7769 - val_loss: 0.5700 - val_recall: 0.9672\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5128 - recall: 0.9318 - val_loss: 0.5471 - val_recall: 0.8689\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5394 - recall: 0.9153 - val_loss: 0.5475 - val_recall: 0.8689\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5201 - recall: 0.8923 - val_loss: 0.5406 - val_recall: 0.8361\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5097 - recall: 0.8709 - val_loss: 0.5406 - val_recall: 0.7377\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5114 - recall: 0.8707 - val_loss: 0.5403 - val_recall: 0.8689\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5065 - recall: 0.9071 - val_loss: 0.5392 - val_recall: 0.8689\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5186 - recall: 0.9441 - val_loss: 0.5370 - val_recall: 0.8689\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5134 - recall: 0.9631 - val_loss: 0.5508 - val_recall: 0.2131\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5222 - recall: 0.5775 - val_loss: 0.5470 - val_recall: 0.9672\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5012 - recall: 0.8901 - val_loss: 0.5732 - val_recall: 0.9672\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5029 - recall: 0.9248 - val_loss: 0.5320 - val_recall: 0.8689\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5238 - recall: 0.9579 - val_loss: 0.5345 - val_recall: 0.9672\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5157 - recall: 0.9623 - val_loss: 0.5420 - val_recall: 0.9672\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5154 - recall: 0.9362 - val_loss: 0.5349 - val_recall: 0.9672\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5112 - recall: 0.9594 - val_loss: 0.5274 - val_recall: 0.8689\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4957 - recall: 0.9331 - val_loss: 0.5304 - val_recall: 0.7213\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4981 - recall: 0.8502 - val_loss: 0.5512 - val_recall: 0.9672\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5157 - recall: 0.9486 - val_loss: 0.5252 - val_recall: 0.8197\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5030 - recall: 0.8362 - val_loss: 0.5519 - val_recall: 0.9672\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4919 - recall: 0.9025 - val_loss: 0.5264 - val_recall: 0.9672\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5111 - recall: 0.9371 - val_loss: 0.5450 - val_recall: 0.9672\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5253 - recall: 0.9340 - val_loss: 0.5379 - val_recall: 0.9672\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4795 - recall: 0.9731 - val_loss: 0.5220 - val_recall: 0.7377\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5072 - recall: 0.8031 - val_loss: 0.5378 - val_recall: 0.9672\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5152 - recall: 0.9107 - val_loss: 0.5311 - val_recall: 0.9672\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5059 - recall: 0.9226 - val_loss: 0.5571 - val_recall: 0.9672\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5007 - recall: 0.9426 - val_loss: 0.5173 - val_recall: 0.9344\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4908 - recall: 0.9616 - val_loss: 0.5148 - val_recall: 0.8689\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5192 - recall: 0.9433 - val_loss: 0.5135 - val_recall: 0.8689\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4791 - recall: 0.9341 - val_loss: 0.5168 - val_recall: 0.9672\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4937 - recall: 0.9526 - val_loss: 0.5297 - val_recall: 0.9672\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4804 - recall: 0.9572 - val_loss: 0.5107 - val_recall: 0.8689\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4888 - recall: 0.9411 - val_loss: 0.5272 - val_recall: 0.9672\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4846 - recall: 0.9820 - val_loss: 0.5134 - val_recall: 0.7705\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5025 - recall: 0.8305 - val_loss: 0.5136 - val_recall: 0.9672\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5045 - recall: 0.9605 - val_loss: 0.5121 - val_recall: 0.9672\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4652 - recall: 0.9582 - val_loss: 0.5104 - val_recall: 0.9672\n"
     ]
    }
   ],
   "source": [
    "model1 = FirstNN(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "Now, we will dive into Hyperparameter Tuning using 2 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperModel(hp):\n",
    "    model = Sequential()\n",
    "    # Tune the number of units in the first hidden layer\n",
    "    hp_units_1 = hp.Int('units_1', min_value=10, max_value=100, step=10)\n",
    "    model.add(Dense(units=hp_units_1, activation='relu', input_dim=X_train.shape[1]))\n",
    "    \n",
    "    # Tune the number of units in the second hidden layer\n",
    "    hp_units_2 = hp.Int('units_2', min_value=10, max_value=100, step=10)\n",
    "    model.add(Dense(units=hp_units_2, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[Recall()])\n",
    "    return model\n",
    "tuner = RandomSearch(\n",
    "    HyperModel,\n",
    "    objective='val_recall',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 15s]\n",
      "val_recall: 0.9562841455141703\n",
      "\n",
      "Best val_recall So Far: 1.0\n",
      "Total elapsed time: 00h 02m 33s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.7391 - recall_2: 0.4059 - val_loss: 0.6894 - val_recall_2: 0.8852\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6794 - recall_2: 0.3616 - val_loss: 0.6685 - val_recall_2: 0.2459\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6785 - recall_2: 0.4833 - val_loss: 0.6573 - val_recall_2: 0.0492\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6582 - recall_2: 0.5904 - val_loss: 0.6588 - val_recall_2: 0.7377\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6440 - recall_2: 0.6940 - val_loss: 0.7166 - val_recall_2: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6513 - recall_2: 0.8512 - val_loss: 0.6358 - val_recall_2: 0.3443\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6316 - recall_2: 0.4390 - val_loss: 0.6327 - val_recall_2: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6298 - recall_2: 0.5091 - val_loss: 0.6376 - val_recall_2: 0.8689\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6017 - recall_2: 0.8091 - val_loss: 0.6311 - val_recall_2: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6033 - recall_2: 0.5031 - val_loss: 0.6334 - val_recall_2: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5972 - recall_2: 0.4855 - val_loss: 0.5974 - val_recall_2: 0.7541\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5747 - recall_2: 0.8290 - val_loss: 0.6108 - val_recall_2: 0.9016\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5593 - recall_2: 0.8453 - val_loss: 0.5903 - val_recall_2: 0.7213\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5648 - recall_2: 0.8108 - val_loss: 0.5873 - val_recall_2: 0.8689\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5545 - recall_2: 0.8566 - val_loss: 0.5910 - val_recall_2: 0.9016\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5473 - recall_2: 0.8360 - val_loss: 0.6305 - val_recall_2: 0.9672\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5589 - recall_2: 0.8951 - val_loss: 0.5598 - val_recall_2: 0.8689\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5178 - recall_2: 0.8972 - val_loss: 0.5477 - val_recall_2: 0.7541\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5436 - recall_2: 0.8731 - val_loss: 0.5724 - val_recall_2: 0.9016\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5154 - recall_2: 0.9034 - val_loss: 0.5515 - val_recall_2: 0.9016\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5139 - recall_2: 0.9071 - val_loss: 0.5762 - val_recall_2: 0.9672\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5148 - recall_2: 0.8856 - val_loss: 0.5302 - val_recall_2: 0.8689\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5290 - recall_2: 0.7052 - val_loss: 0.5216 - val_recall_2: 0.8689\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5044 - recall_2: 0.9054 - val_loss: 0.5186 - val_recall_2: 0.8525\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5191 - recall_2: 0.7072 - val_loss: 0.5943 - val_recall_2: 0.9672\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5231 - recall_2: 0.8012 - val_loss: 0.5332 - val_recall_2: 0.9016\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5049 - recall_2: 0.8943 - val_loss: 0.5150 - val_recall_2: 0.9672\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4977 - recall_2: 0.8866 - val_loss: 0.5107 - val_recall_2: 0.6230\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4760 - recall_2: 0.8528 - val_loss: 0.5314 - val_recall_2: 0.9672\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4709 - recall_2: 0.9407 - val_loss: 0.5587 - val_recall_2: 0.1148\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5435 - recall_2: 0.6050 - val_loss: 0.5501 - val_recall_2: 0.9672\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4971 - recall_2: 0.8673 - val_loss: 0.4963 - val_recall_2: 0.7705\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4948 - recall_2: 0.7976 - val_loss: 0.5352 - val_recall_2: 0.9672\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4584 - recall_2: 0.9221 - val_loss: 0.4990 - val_recall_2: 0.9672\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4975 - recall_2: 0.8464 - val_loss: 0.5587 - val_recall_2: 0.9672\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4678 - recall_2: 0.9234 - val_loss: 0.4895 - val_recall_2: 0.9672\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4930 - recall_2: 0.8876 - val_loss: 0.5398 - val_recall_2: 0.9672\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5098 - recall_2: 0.8909 - val_loss: 0.5239 - val_recall_2: 0.0000e+00\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5004 - recall_2: 0.5885 - val_loss: 0.5083 - val_recall_2: 0.9672\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4878 - recall_2: 0.9263 - val_loss: 0.4814 - val_recall_2: 0.7213\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4726 - recall_2: 0.8705 - val_loss: 0.4769 - val_recall_2: 0.9672\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4762 - recall_2: 0.8211 - val_loss: 0.5087 - val_recall_2: 0.9672\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5158 - recall_2: 0.7268 - val_loss: 0.4931 - val_recall_2: 0.4590\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5136 - recall_2: 0.7809 - val_loss: 0.5308 - val_recall_2: 0.9672\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4769 - recall_2: 0.9150 - val_loss: 0.4925 - val_recall_2: 0.9672\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4924 - recall_2: 0.9305 - val_loss: 0.5000 - val_recall_2: 0.9672\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5102 - recall_2: 0.8787 - val_loss: 0.4809 - val_recall_2: 0.9672\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4741 - recall_2: 0.8533 - val_loss: 0.4699 - val_recall_2: 0.9508\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4662 - recall_2: 0.9153 - val_loss: 0.4778 - val_recall_2: 0.9672\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4556 - recall_2: 0.9031 - val_loss: 0.4805 - val_recall_2: 0.9672\n"
     ]
    }
   ],
   "source": [
    "modelBest = tuner.hypermodel.build(best_hps)\n",
    "history = modelBest.fit(X_train, y_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "AUC: 0.70\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, (model1.predict(X_test) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step\n",
      "AUC: 0.76\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y2, (model1.predict(inputs) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step\n",
      "Accuracy: 0.7\n",
      "[[48 54]\n",
      " [ 6 92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.47      0.62       102\n",
      "           1       0.63      0.94      0.75        98\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.76      0.70      0.68       200\n",
      "weighted avg       0.76      0.70      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(model1,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step\n",
      "Accuracy: 0.7524271844660194\n",
      "[[306 233]\n",
      " [ 22 469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.57      0.71       539\n",
      "           1       0.67      0.96      0.79       491\n",
      "\n",
      "    accuracy                           0.75      1030\n",
      "   macro avg       0.80      0.76      0.75      1030\n",
      "weighted avg       0.81      0.75      0.74      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(model1,inputs,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "AUC: 0.71\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, (modelBest.predict(X_test) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step\n",
      "AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y2, (modelBest.predict(inputs) > 0.5).astype(int).flatten())\n",
    "print(\"AUC: {:.2f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step\n",
      "Accuracy: 0.705\n",
      "[[50 52]\n",
      " [ 7 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.49      0.63       102\n",
      "           1       0.64      0.93      0.76        98\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.76      0.71      0.69       200\n",
      "weighted avg       0.76      0.70      0.69       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(modelBest,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step\n",
      "Accuracy: 0.7611650485436893\n",
      "[[317 222]\n",
      " [ 24 467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.59      0.72       539\n",
      "           1       0.68      0.95      0.79       491\n",
      "\n",
      "    accuracy                           0.76      1030\n",
      "   macro avg       0.80      0.77      0.76      1030\n",
      "weighted avg       0.81      0.76      0.75      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TestModelAccuracy(modelBest,inputs,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "def find_optimal_threshold_nn(model, X_test, y_test, min_precision=0.7):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for a given neural network model to maximize recall while maintaining a minimum precision.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained neural network model\n",
    "        The trained neural network model.\n",
    "    X_test : numpy array or pandas DataFrame\n",
    "        The test features.\n",
    "    y_test : numpy array or pandas Series\n",
    "        The true labels for the test set.\n",
    "    min_precision : float\n",
    "        The minimum acceptable precision value.\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The optimal threshold value that maximizes recall while maintaining the minimum precision.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the predicted probabilities for the positive class\n",
    "    y_prob = model.predict(X_test).ravel()\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "    # Initialize variables to track the optimal threshold\n",
    "    optimal_threshold = 0.5  # Default threshold\n",
    "    max_recall = 0\n",
    "\n",
    "    # Find the threshold that maximizes recall while keeping precision above min_precision\n",
    "    for i in range(len(precision)):\n",
    "        if precision[i] >= min_precision:\n",
    "            optimal_threshold = thresholds[i]\n",
    "            max_recall = recall[i]\n",
    "            break\n",
    "\n",
    "    print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "    print(f\"Precision at Optimal Threshold: {precision[i]}\")\n",
    "    print(f\"Max Recall at Optimal Threshold: {max_recall}\")\n",
    "\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step\n",
      "Optimal Threshold: 0.6214653253555298\n",
      "Precision at Optimal Threshold: 0.7053571428571429\n",
      "Max Recall at Optimal Threshold: 0.8061224489795918\n"
     ]
    }
   ],
   "source": [
    "optimal_threshold = find_optimal_threshold_nn(modelBest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def plot_precision_recall_curve_nn(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Plot the precision-recall curve for a given neural network model with AUC.\n",
    "\n",
    "    Parameters:\n",
    "    model : trained neural network model\n",
    "        The trained neural network model.\n",
    "    X_test : numpy array or pandas DataFrame\n",
    "        The test features.\n",
    "    y_test : numpy array or pandas Series\n",
    "        The true labels for the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the predicted probabilities for the positive class\n",
    "    y_prob = model.predict(X_test).ravel()  # Flatten if necessary\n",
    "\n",
    "    # Compute precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "    # Compute the AUC\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    # Plot the precision-recall curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve (AUC = {pr_auc:.2f})')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve_nn(modelBest, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('NN_Model.pkl', 'wb') as file:\n",
    "    pickle.dump((modelBest,optimal_threshold), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5493607,
     "sourceId": 9102667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
